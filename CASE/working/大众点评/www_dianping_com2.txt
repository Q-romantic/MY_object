# -*- coding: utf-8 -*-
import requests
import base64
import zlib
import time
from jsonpath import jsonpath
import random
import re
import os
import json
from lxml import etree
from threading import Timer
from PIL import ImageFont, Image, ImageDraw
from io import BytesIO
import ddddocr
from fontTools.ttLib import TTFont
from fontTools.ttLib.woff2 import decompress

# url = 'http://www.dianping.com/shop/H3SyNUSShP5BYm87'
# url = 'http://www.dianping.com/shop/l3n4jWYuQPhDSKsE'
url = 'http://www.dianping.com/shop/ivbjaqnpAdOCsiY4'
url_i = 'http://www.dianping.com/ajax/json/shopDynamic/basicHideInfo'
url_s = 'http://www.dianping.com/ajax/json/shopDynamic/reviewAndStar'
url_p = 'http://www.dianping.com/ajax/json/shopDynamic/allReview'

info = str(
    {"rId": "", "ts": int(time.time() * 1000), "cts": int(time.time() * 1000) + 100, "brVD": [], "brR": [], "bI": [],
     "mT": [], "kT": [], "aT": [], "tT": [], "sign": 'eJwDAAAAAAE='}).encode()
token = base64.b64encode(zlib.compress(info)).decode()

full_url = [
    'http://www.dianping.com/ajax/json/shopDynamic/fav',
    'http://www.dianping.com/ajax/json/shopDynamic/reviewAndStar',
    'http://www.dianping.com/ajax/json/shopDynamic/shopAlbum',
    'http://www.dianping.com/ajax/json/shopDynamic/searchPromo',
    'http://www.dianping.com/ajax/json/shopDynamic/shopTabs',
    'http://www.dianping.com/ajax/json/shopDynamic/addReview',
    'http://www.dianping.com/ajax/json/shopDynamic/myReview',
    'http://www.dianping.com/ajax/json/shopDynamic/friendReviews',
    'http://www.dianping.com/ajax/json/shopDynamic/allReview',
    'http://www.dianping.com/ajax/json/shopDynamic/basicHideInfo',
    'http://www.dianping.com/ajax/json/shopDynamic/shopAside',
    'http://www.dianping.com/ajax/json/shopDynamic/promoInfo',

]

full_data = {
    'shopId': url[-16:],  # 数据由字典source_data_2更新
    'uuid': 'd0bc69ea-087f-04f7-ca47-ca53213761fb.1637378507',
    'platform': '1',
    'partner': '150',
    'optimusCode': '10',
    'originUrl': 'http://www.dianping.com/shop/' + url[-16:],
    'cityId': '2',  # 数据由字典source_data_1更新
    'mainCategoryId': '114',  # 数据由字典source_data_2更新
    'defaultPic': '',  # 数据由字典source_data_2更新
    'power': '5',  # 数据由字典source_data_2更新
    'shopType': '10',  # 数据由字典source_data_2更新
    'shopName': '',  # 数据由字典source_data_2更新
    'shopCityId': '2',  # 数据由字典source_data_2更新
    'cityName': '北京',  # 数据由字典source_data_1更新
    'shopGroupId': '',  # 数据由字典source_data_2更新
    'pn': '1',
    'tcv': 'ro4xcqvykp',
    'mainRegionId': '1489',  # 数据由字典source_data_2更新
    'cityEnName': 'beijing',  # 数据由字典source_data_1更新
    '_token': token,
}

USER_AGENT_LIST = [
    'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3451.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:57.0) Gecko/20100101 Firefox/57.0',
    'Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1500.71 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.2999.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.70 Safari/537.36',
    'Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.4; en-US; rv:1.9.2.2) Gecko/20100316 Firefox/3.6.2',
    'Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.155 Safari/537.36 OPR/31.0.1889.174',
    'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 1.1.4322; MS-RTC LM 8; InfoPath.2; Tablet PC 2.0)',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36 OPR/55.0.2994.61',
    'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/14.0.814.0 Safari/535.1',
    'Mozilla/5.0 (Macintosh; U; PPC Mac OS X; ja-jp) AppleWebKit/418.9.1 (KHTML, like Gecko) Safari/419.3',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.134 Safari/537.36',
    'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0; Touch; MASMJS)',
    'Mozilla/5.0 (X11; Linux i686) AppleWebKit/535.21 (KHTML, like Gecko) Chrome/19.0.1041.0 Safari/535.21',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36',
    'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3451.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:57.0) Gecko/20100101 Firefox/57.0',
    'Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1500.71 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.2999.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.70 Safari/537.36',
    'Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.4; en-US; rv:1.9.2.2) Gecko/20100316 Firefox/3.6.2',
    'Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.155 Safari/537.36 OPR/31.0.1889.174',
    'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 1.1.4322; MS-RTC LM 8; InfoPath.2; Tablet PC 2.0)',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36 OPR/55.0.2994.61',
    'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/14.0.814.0 Safari/535.1',
    'Mozilla/5.0 (Macintosh; U; PPC Mac OS X; ja-jp) AppleWebKit/418.9.1 (KHTML, like Gecko) Safari/419.3',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.134 Safari/537.36',
    'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0; Touch; MASMJS)',
    'Mozilla/5.0 (X11; Linux i686) AppleWebKit/535.21 (KHTML, like Gecko) Chrome/19.0.1041.0 Safari/535.21',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36',
    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4093.3 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko; compatible; Swurl) Chrome/77.0.3865.120 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4086.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:75.0) Gecko/20100101 Firefox/75.0',
    'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) coc_coc_browser/91.0.146 Chrome/85.0.4183.146 Safari/537.36',
    'Mozilla/5.0 (Windows; U; Windows NT 5.2; en-US) AppleWebKit/537.36 (KHTML, like Gecko) Safari/537.36 VivoBrowser/8.4.72.0 Chrome/62.0.3202.84',
    'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.101 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36 Edg/87.0.664.60',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.16; rv:83.0) Gecko/20100101 Firefox/83.0',
    'Mozilla/5.0 (X11; CrOS x86_64 13505.63.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:68.0) Gecko/20100101 Firefox/68.0',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.101 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36 OPR/72.0.3815.400',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.101 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36',
]
PROXY_LIST = [
    '101.32.223.241:60080',
    '101.132.189.87:9090',
    '221.122.91.75:10286',
    '101.132.189.87:9090',
    '106.54.141.54:3128',
    '124.70.5.25:7777',
    '120.76.244.188:8080',
    '106.54.128.253:999',
    '183.172.236.158:10080',
    '101.132.189.87:9090',
    '101.132.189.87:9090',
    '183.172.236.158:10080',
    '183.173.119.127:7890',
    '183.172.236.158:10080',
    '101.132.100.26:80',
    '124.204.33.162:8000',
    '101.132.100.26:80',
    '101.132.189.87:9090',
    '183.172.236.158:10080',
    '106.54.128.253:999',
    '106.54.128.253:999',
    '183.173.121.168:10080',
    '221.122.91.75:10286',
    '124.204.33.162:8000',
    '101.200.73.201:8080',
    '101.132.186.39:9090',
]
proxy = random.choice(PROXY_LIST)
headers = {
    'user-agent': random.choice(USER_AGENT_LIST)
}
proxies = {
    "http": "http://" + proxy,
    "https": "http://" + proxy,
}


def get_home_page():  #
    while 1:
        headers = {
            'user-agent': random.choice(USER_AGENT_LIST)
        }
        resp = requests.get(url, headers=headers)
        if resp.status_code == 200:
            break
    return resp


def font_to_img(_code, filename):
    """将字体画成图片"""
    img_size = 1024
    img = Image.new('1', (img_size, img_size), 255)
    draw = ImageDraw.Draw(img)
    font = ImageFont.truetype(filename, int(img_size * 0.7))
    txt = chr(_code)
    x, y = draw.textsize(txt, font=font)
    draw.text(((img_size - x) // 2, (img_size - y) // 2), txt, font=font, fill=0)
    return img


def identify_word(_ttf_path):
    """识别ttf字体结果"""
    dic = {}
    font = TTFont(_ttf_path)
    ocr = ddddocr.DdddOcr()
    for cmap_code, glyph_name in font.getBestCmap().items():
        bytes_io = BytesIO()
        pil = font_to_img(cmap_code, _ttf_path)
        pil.save(bytes_io, format="PNG")
        word = ocr.classification(bytes_io.getvalue())  # 识别字体
        # print(cmap_code, glyph_name, word)
        # dic.update({glyph_name: word})
        dic[glyph_name] = word
    # print(dic)
    return dic


def get_dic(name, url):
    resp = requests.get(url)
    name = 'tmp_' + name + '_' + url[-13:]
    # print(resp.content)
    with open(name, mode='wb') as f:
        f.write(resp.content)
    dic = identify_word(name)
    return dic


def get_big_dic(data):
    filename = 'big_dic_data.txt'
    xml = etree.HTML(data.text)
    link_css_font = 'http:' + xml.xpath('/html/head/link[10]/@href')[0]
    print(link_css_font)
    # source_s = xml.xpath('/html/head/script[3]/text()')[0][24:-1]
    # source_data_1 = eval(source_s)  # 字典形式字符串转字典
    # # print(source_data_1)
    # source_s = xml.xpath('//*[@id="top"]/script[1]/text()')[0][22:-4]
    # source_data_2 = {}
    # for i in source_s.replace(': "', ':').replace('",', ',').replace(": '", ":").replace("',", ",").replace(':"', ':').replace(', ', ',').replace(':{ ', ':"{').replace('" }', '}"').split(','):
    #     li = i.split(':')
    #     source_data_2[li[0]] = li[1]
    # # print(source_data_2)
    # full_data.update(source_data_1), full_data.update(source_data_2)  # 更新full_data字典
    # # print(full_data)
    if not os.path.exists(filename):
        # data.encoding = 'utf-8'
        dic = {}
        resp = requests.get(link_css_font, headers=headers).text
        obj1 = re.compile("font-family: 'PingFangSC-Regular-(?P<name>.*?)';", re.S)
        names = obj1.findall(resp)
        obj2 = re.compile(',url(?P<url>.*?);', re.S)
        urls = obj2.findall(resp)
        for i in range(len(names)):
            font_url = 'http:' + urls[i][2:-2]
            print(names[i], font_url)
            dic[names[i]] = get_dic(names[i], font_url)
        with open(filename, 'w', encoding="utf-8") as f:
            f.write(json.dumps(dic, ensure_ascii=False))  # 将ensure_ascii设置为False，此时存入json的中文可正常显示。
        # print(dic['shopdesc']["unie07f"])
    else:
        with open(filename, "r", encoding="utf-8") as f:
            dic = eval(f.read())
            # print(dic['shopdesc']["unie07f"])
            return dic


def parse_home_page_data(data):
    xml = etree.HTML(data.text)
    # print(data.text)
    source_s = xml.xpath('/html/head/script[3]/text()')[0][24:-1]
    source_data_1 = eval(source_s)  # 字典形式字符串转字典
    # print(source_data_1)
    source_s = xml.xpath('//*[@id="top"]/script[1]/text()')[0][21:-1]
    source_data_2 = {}
    for i in source_s.replace(': "', ':').replace('",', ',').replace(": '", ":").replace("',", ",").replace(':"', ':').replace(', ', ',').replace(':{ ',
                                                                                                                                                  ':"{').replace(
            '" }', '}"').replace(': ', ':').split(','):
        li = i.split(':')
        source_data_2[li[0]] = li[1]
    # print(source_data_2)
    full_data.update(source_data_2), full_data.update(source_data_1)  # 更新full_data字典
    # print(full_data)
    obj = re.compile('<span class="info-name">营业时间：</span>.*?<span class="item">(?P<li>.*?)</span>', re.S)
    T = obj.search(data.text).group('li')
    T = str_to_dic_data(T)
    print('营业时间：' + T)
    # return link_css_font


def str_to_dic_data(s):
    s1 = s.replace('<e class="address">&#x', '|address_uni').replace(';</e>', '|') \
        .replace('<d class="num">&#x', '|num_uni').replace(';</d>', '|') \
        .replace('<svgmtsi class="review">&#x', '|review_uni').replace(';</svgmtsi>', '|') \
        .replace('<svgmtsi class="shopdesc">&#x', '|shopdesc_uni').replace(';</svgmtsi>', '|') \
        .replace('<svgmtsi class="hours">&#x', '|hours_uni').replace(';</svgmtsi>', '|') \
        .replace('<br />', '\n').replace('&nbsp;', '') \
        .split('|')
    li = []
    for i in s1:
        if '_' in i:
            try:
                k = i.split('_')
                i = big_dic[k[0]][k[-1]]
                if i == None:
                    print('no key!')
            except:
                try:
                    k = i.split('_')
                    i = big_dic['address'][k[-1]]
                except:
                    try:
                        k = i.split('_')
                        i = big_dic['num'][k[-1]]
                    except:
                        try:
                            k = i.split('_')
                            i = big_dic['review'][k[-1]]
                        except:
                            try:
                                k = i.split('_')
                                i = big_dic['shopdesc'][k[-1]]
                            except:
                                try:
                                    k = i.split('_')
                                    i = big_dic['hours'][k[-1]]

                                except:
                                    try:
                                        k = i.split('_')
                                        i = big_dic['dishname'][k[-1]]

                                    except:
                                        pass

                                    else:
                                        pass

                                else:
                                    pass

                            else:
                                pass
                        else:
                            pass
                    else:
                        pass
                else:
                    pass

            else:
                pass
        li.append(i)
    s = ''.join(li)
    return s


def get_info():
    print(url_i)
    resp = requests.get(url_i, headers=headers, params=full_data)
    # print(resp.text)
    shopInfo = resp.json()['msg']['shopInfo']
    shopName = shopInfo['shopName']
    branchName = shopInfo['branchName']
    address = shopInfo['address']
    crossRoad = shopInfo['crossRoad']
    phoneNo = shopInfo['phoneNo']
    # print(address)
    print('店名：' + shopName, branchName)
    address = str_to_dic_data(address)
    print('地址：' + address)
    crossRoad = str_to_dic_data(crossRoad)
    print('交叉路：' + crossRoad)
    phoneNo = str_to_dic_data(phoneNo)
    print('电话：' + phoneNo)
    resp2 = requests.get(url_s, headers=headers, params=full_data)
    # print(resp2.text)
    avgPrice = resp2.json()['avgPrice']
    avgPrice = str_to_dic_data(avgPrice)
    print('人均：' + avgPrice + '元')
    defaultReviewCount = resp2.json()['defaultReviewCount']
    defaultReviewCount = str_to_dic_data(defaultReviewCount)
    print('评论量：' + defaultReviewCount)
    shopRefinedScoreValueList = resp2.json()['shopRefinedScoreValueList']
    shopRefinedScoreValueList[0] = str_to_dic_data(shopRefinedScoreValueList[0])
    shopRefinedScoreValueList[1] = str_to_dic_data(shopRefinedScoreValueList[1])
    shopRefinedScoreValueList[2] = str_to_dic_data(shopRefinedScoreValueList[2])
    print('口味：' + shopRefinedScoreValueList[0])
    print('环境：' + shopRefinedScoreValueList[1])
    print('服务：' + shopRefinedScoreValueList[2])


def get_pinglun():
    print(url_p)
    resp = requests.get(url_p, headers=headers, params=full_data)
    # print(resp.json())
    reviewAllDOList = resp.json()['reviewAllDOList']
    for i in reviewAllDOList:
        reviewBody = i['reviewDataVO']['reviewBody']
        userNickName = i['user']['userNickName']
        userId = i['user']['userId']
        userId_url = 'http://www.dianping.com/member/' + str(userId)
        print('评论用户网名：' + userNickName + ' ' + userId_url)
        reviewBody = str_to_dic_data(reviewBody)
        print(reviewBody)
        print('----' * 40)
    print('单页评论量：', len(reviewAllDOList))


print(url)
data = get_home_page()
# print(data.text)
big_dic = get_big_dic(data)
parse_home_page_data(data)
# print(full_data)
get_info()
get_pinglun()
print(big_dic.keys())
# print(big_dic)
